import re
import boto3
from urllib.parse import urlparse

# Initialize Boto3 S3 client
s3_client = boto3.client('s3')

# Regular expression patterns to extract metadata
table_pattern = re.compile(r"Library (\w+) assigned with PARQUET engine\. Found (\d+) table\(s\) in (\d+\.\d+) seconds\.")
dataframe_pattern = r"DataFrame (\w+)\s+\((\d+) rows, (\d+) columns\) saved in [\d.]+ seconds to:\s+'(.+)'"

# Input S3 URI of the log file
s3_uri = 's3://your-bucket-name/path/to/your/log-file.log'

# Parse the S3 URI to extract bucket and key
parsed_uri = urlparse(s3_uri)
s3_bucket = parsed_uri.netloc
s3_key = parsed_uri.path.lstrip('/')

# Read log content from S3
response = s3_client.get_object(Bucket=s3_bucket, Key=s3_key)
log_content = response['Body'].read().decode('utf-8')

# Extract table count and library name
table_matches = table_pattern.findall(log_content)
for library_name, count, _ in table_matches:
    print(f"{library_name} - {count}")

# Extract DataFrame information
dataframe_matches = dataframe_pattern.findall(log_content)
for dataframe_name, rows, columns, _, file_path in dataframe_matches:
    print(f"DataFrame {dataframe_name}: {rows} rows, {columns} columns saved to {file_path}")
