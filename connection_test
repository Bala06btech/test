from pyspark.sql import SparkSession
from datetime import datetime
import json
import pytz
import boto3
import pandas as pd
 
json_file_path = 's3://s3/SampleDB_Conn.json'
csv_output_path = 's3://s3/DB_connection_info.csv'
 
# Initialize Spark session
spark = SparkSession.builder.appName("JDBCConnectionTest").getOrCreate()
 
# Initialize Glue client
glue_client = boto3.client('glue')
connections_data = pd.read_json(json_file_path)
 
# List to store connection information
connection_info = []
 
# Loop through each database.table object and test JDBC connections using Spark
for table_key, table_info in connections_data.items():
    if table_key != "env":
        try:
            connection_name = table_info['conn_name']
            database_name = table_info['databaseName']
            table_name = table_info['dbtable']
            try:
                glue_connection = glue_client.get_connection(Name=connection_name)['Connection']
                # Extract the JDBC URL from the Glue connection
                jdbc_url = glue_connection['ConnectionProperties']['JDBC_CONNECTION_URL']
                username = glue_connection['ConnectionProperties']['USERNAME']
                password = glue_connection['ConnectionProperties']['PASSWORD']
 
                # Attempt to establish the connection
                try:
                    jdbc_df = spark.read \
                        .format("jdbc") \
                        .option("url", jdbc_url) \
                        .option("dbtable", table_name) \
                        .option("user", username) \
                        .option("password", password) \
                        .load()
                    # Update connection status to "success"
                    connection_status = "success"
                    has_table = "Yes"
                    has_data = "Yes" if not jdbc_df.isEmpty() else "No"
                    connection_info.append((connection_name, connection_status, table_key, has_table, has_data))
                    print(connection_name, connection_status, table_key, has_table, has_data)
                except Exception as e:
                    # Append connection information to the list indicating an error
                    connection_status = "failure_in_jdbc"
                    if "doesn't exist" in str(e):
                        has_table = 'No'
                    else:
                        has_table = 'N/A'
                   
                    connection_info.append((connection_name, connection_status, table_key, has_table, "N/A"))
                    print(connection_name, connection_status, table_key, has_table, "N/A")
 
            except Exception as e:
                # Append connection information to the list indicating a connection issue
                connection_info.append((connection_name, "failure_glue_connection", table_key, "N/A", "N/A"))
                print(connection_name, "failure_glue_connection", table_key, "N/A", "N/A")
        except KeyError as e:
            # Append connection information to the list indicating a KeyError
            connection_info.append((connection_name, "failure_reading_json", table_key, "N/A", "N/A"))
            print(connection_name, "failure_reading_json", table_key, "N/A", "N/A")
 
# Create a DataFrame from the connection information
columns = ["Connection", "Connection Status", "Table Key", "Has Table", "Has Data"]
connection_df = pd.DataFrame(connection_info, columns=columns)
 
# Write the DataFrame to a CSV file
connection_df.to_csv(csv_output_path, index=False)
 
tz_NY = pytz.timezone('America/New_York')
datetime_NY = datetime.now(tz_NY)
 
print("Connection information written to CSV : ", csv_output_path )
print('Output file generated on : ', datetime_NY.strftime("%Y-%m-%d %H:%M:%S"))
