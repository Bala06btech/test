from pyspark.sql import SparkSession
import json

# Initialize Spark session
spark = SparkSession.builder.appName("JDBCConnectionTest").getOrCreate()
json_file_path = 's3://path/1.json'

# Load connection configurations from the JSON file
with open(json_file_path) as json_file:
    connections_data = json.load(json_file)

# Loop through each database.table object and test JDBC connections using Spark
for table_key, table_info in connections_data.items():
    if table_key != "env":
        try:
            connection_name = table_info['conn_name']
            database_name = table_info['database_name']
            table_name = table_info['dbtable']

            # Get connection details from Glue
            glue_connection = glue_client.get_connection(Name=connection_name)['Connection']

            # Extract the JDBC URL from the Glue connection
            jdbc_url = glue_connection['ConnectionProperties']['JDBC_CONNECTION_URL']
            jdbc_url = glue_connection['ConnectionProperties']['Username']
            jdbc_url = glue_connection['ConnectionProperties']['Password']
                                                               
            print(connection_name, database_name, table_name, JDBC_CONNECTION_URL, username, password)
