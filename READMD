import sys
import boto3
import pandas as pd
from urllib.parse import urlparse

bucket_name = '<bucket>'
input_file = '<input_path>'
output_file = '<output_path>'

# Create an S3 client
s3 = boto3.client('s3')

def check_file_available(object_key):
    try:
        s3.head_object(Bucket=bucket_name, Key=object_key)
        return 'Yes'
    except Exception as e:
        return 'No'

# Read input file into a list
with open(input_file, 'r') as f:
    lines = f.readlines()

# Check availability for each object
results = []

for line in lines:
    object_key = line.strip()
    if object_key.endswith('/'):
        object_key = object_key.rstrip('/')  # Remove trailing '/'
        result = check_file_available(object_key)
        results.append((object_key + '/', result))
    else:
        result = check_file_available(object_key)
        results.append((object_key, result))

# Create a Pandas DataFrame
pandas_df = pd.DataFrame(results, columns=['file_name', 'file_available'])

# Save DataFrame to CSV
pandas_df.to_csv(output_file, index=False)
print('Check the output file')
