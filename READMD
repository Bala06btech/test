import boto3
import pandas as pd

bucket_name = '<bucket>'
input_file = '<input_path>'
output_file = '<output_path>'

# Create an S3 client
s3 = boto3.client('s3')

def check_folder_available(folder_key):
    try:
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_key, Delimiter='/')
        return 'Yes' if 'Contents' in response or 'CommonPrefixes' in response else 'No'
    except Exception as e:
        return 'No'

def check_file_available(object_key):
    try:
        s3.head_object(Bucket=bucket_name, Key=object_key)
        return 'Yes'
    except Exception as e:
        return 'No'

# Read input file into a list
with open(input_file, 'r') as f:
    lines = f.readlines()

# Check availability for each object
results = []

for line in lines:
    object_key = line.strip()

    if object_key.endswith('/'):
        result = check_folder_available(object_key)
    else:
        result = check_file_available(object_key)

    results.append((object_key, result))

# Create a Pandas DataFrame
pandas_df = pd.DataFrame(results, columns=['file_name', 'file_available'])

# Save DataFrame to CSV
pandas_df.to_csv(output_file, index=False)
print('Check the output file')
