from pyspark.sql import SparkSession
from pyspark.sql.functions import date_format, to_date, lit

# Create a Spark session
spark = SparkSession.builder.appName("DateExample").getOrCreate()

# Create a DataFrame with the given date
data = [("2024-01-01",)]
df = spark.createDataFrame(data, ["date_str"])

# Convert the string date to a date type
df = df.withColumn("date", to_date(df["date_str"], "yyyy-MM-dd"))

# Format the date to "Apr 2024"
df = df.withColumn("formatted_date", date_format(df["date"], "MMM yyyy"))

# Collect the result
result = df.select("formatted_date").collect()

# Get the value as a string
formatted_date = result[0]["formatted_date"]
print(formatted_date)



import boto3

# Initialize a boto3 S3 client
s3_client = boto3.client('s3')

# Define the source and destination details
source_bucket_name = 'your-source-bucket-name'
source_key_prefix = 'your-source-folder/'  # Adjust if the file is in a folder
destination_bucket_name = 'your-destination-bucket-name'
destination_key = 'your-destination-folder/abc.csv'  # New file name and path

# Find the file starting with "part-0000" in the source folder
response = s3_client.list_objects_v2(Bucket=source_bucket_name, Prefix=source_key_prefix)

for obj in response.get('Contents', []):
    file_name = obj['Key']
    if file_name.startswith(source_key_prefix + "part-0000"):
        # Copy the file to the new location with the new name
        copy_source = {
            'Bucket': source_bucket_name,
            'Key': file_name
        }
        s3_client.copy_object(Bucket=destination_bucket_name, CopySource=copy_source, Key=destination_key)
        
        # Delete the original file
        s3_client.delete_object(Bucket=source_bucket_name, Key=file_name)
        
        print(f"File {file_name} has been moved and renamed to {destination_key}")
        break  # Assuming only one file matches the pattern, exit the loop
else:
    print("No file starting with 'part-0000' found.")



// Convert the filter date to both date formats
val formattedFilterDate1 = spark.sql(s"SELECT TO_DATE('$filterDate', 'ddMMMyyyy') as filter_date").first().getAs[Date]("filter_date")
val formattedFilterDate2 = spark.sql(s"SELECT TO_DATE('$filterDate', 'yyyy-MM-dd') as filter_date").first().getAs[Date]("filter_date")

// Apply the dynamic transformation using when and otherwise
val transformedDF = df.withColumn("transformed_date_column",
  when(date_format(col("date_column"), "yyyyMMdd") === date_format(lit(formattedFilterDate1), "yyyyMMdd"), to_date(lit(filterDate), "yyyyMMdd"))
    .otherwise(when(date_format(col("date_column"), "yyyy-MM-dd") === date_format(lit(formattedFilterDate2), "yyyy-MM-dd"), col("date_column"))
    .otherwise(lit(null)))
)


result_df = spark.sql("""
    SELECT original_date,
           to_date(original_date, 'dd/MM/yyyy') AS parsed_date,
           date_format(to_date(original_date, 'dd/MM/yyyy'), 'yyyy-MM-dd') AS formatted_date
    FROM date_table
""")

WHERE DATE(SUBSTR(your_column, 1, 4) || '-' || SUBSTR(your_column, 5, 2) || '-' || SUBSTR(your_column, 7, 2)) > DATE('1960-01-01');


from pyspark.sql.functions import lit

def fill_null_if_column_not_exists(df, column_name):
    if column_name not in df.columns:
        df = df.withColumn(column_name, lit(None).cast("string"))
    return df



df = df.withColumn("timestamp", from_unixtime(unix_timestamp(col("timestamp_str"), "ddMMMyyyy:HH:mm:ss.SSS")))

import boto3

def get_logs_between_times(log_group_name, start_time, end_time):
    client = boto3.client('logs')

    response = client.get_log_events(
        logGroupName=log_group_name,
        startTime=start_time,
        endTime=end_time,
        limit=10  # Adjust the limit as needed
    )

    return response['events']

# Example time range: '1900-01-01' to '2099-01-01'
log_group_name = '/aws-glue/jobs/output'
start_time = 0  # '1900-01-01' in milliseconds since epoch
end_time = 4102406399000  # '2099-01-01' in milliseconds since epoch

log_events = get_logs_between_times(log_group_name, start_time, end_time)

for event in log_events:
    print(event['message'])



aws s3api list-object-versions --bucket your-bucket-name --prefix your-folder-path/ --output json --query "Versions[?IsDeleteMarker==true && LastModified<= 'desired-time']"

aws glue list-jobs

aws glue get-job --job-name your-job-name

for job_name in $(aws glue list-jobs --output text --query 'JobNames'); do
    script_location=$(aws glue get-job --job-name $job_name --query 'Job.Command.ScriptLocation' --output text)
    echo "Job Name: $job_name, Script Location: $script_location"
done

@echo off

setlocal enabledelayedexpansion
set "count=0"

for /f "delims=" %%A in ('aws glue list-jobs --output text --query "JobNames[]"') do (
    if !count! gtr 0 (
        echo.
    )
    echo %%A
    set /a "count+=1"
)


@echo off

setlocal enabledelayedexpansion

for /f "delims=" %%A in (glue_job_names.txt) do (
    set "job_name=%%A"
    for /f "delims=" %%B in ('aws glue get-job --job-name "!job_name!" --query "Job.Command.ScriptLocation" --output text') do (
        echo Job Name: !job_name!, Script Location: %%B
    )
)


import boto3

# Initialize Glue client
glue_client = boto3.client('glue')

# Retrieve all Glue jobs
all_jobs = []
next_token = None

while True:
    if next_token:
        response = glue_client.get_jobs(NextToken=next_token)
    else:
        response = glue_client.get_jobs()

    all_jobs.extend(response['Jobs'])
    next_token = response.get('NextToken')

    if not next_token:
        break

# Print job names and script locations
for job in all_jobs:
    job_name = job['Name']
    script_location = job['Command']['ScriptLocation']
    print(f"Job Name: {job_name}, Script Location: {script_location}")




response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

# Iterate through the objects
for obj in response.get('Contents', []):
    # Check if the object is a .py file
    if obj['Key'].endswith('.py'):
        # Download the .py file
        file_contents = s3.get_object(Bucket=bucket_name, Key=obj['Key'])['Body'].read().decode('utf-8')
        
        # Check if the file contains the desired line
        if 'xlsx' in file_contents:
            print(f"File {obj['Key']} contains 'xlsx'")
